{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"raw_data.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute('select * from data where category is \"5\" and Title not like \"%정서장애%\" and Content not like \"%정서장애%\" and Content not like \"%감정장애%\" and Content not like \"%기분장애%\" and Content not like \"%가을타다%\" and Content not like \"%청동장애%\" and Content not like \"%계절성%\" and \\\n",
    "Title not like \"%ADHD%\" and Content not like \"%ADHD%\" and Content not like \"%주의력%\" and Content not like \"%부주의%\" and Content not like \"%주의점%\" and Content not like \"%산만%\" and Content not like \"%과잉행동%\" and Content not like \"%충동%\"  and Content not like \"%수다%\" and \\\n",
    "Title not like \"%조현병%\" and Content not like \"%조현병%\" and Content not like \"%망상%\" and Content not like \"%환각%\" and Content not like \"%사고장애%\" and Content not like \"%정신운동장애%\" and Content not like \"%인사불성%\" and Content not like \"%강직%\" and Content not like \"%따라함%\" and \\\n",
    "Title not like \"%강박장애%\" and Content not like \"%강박장애%\" and Content not like \"%강박%\" and Content not like \"%제자리%\" and Content not like \"%집착%\" and Content not like \"%결벽증%\" and Content not like \"%결벽%\" and Content not like \"%깔끔%\" and Content not like \"%원위치%\" and \\\n",
    "Title not like \"%인격장애%\" and Content not like \"%인격장애%\" and Content not like \"%성격장애%\" and Content not like \"%변덕%\" and Content not like \"%불안정%\" and Content not like \"%양가감정%\" and Content not like \"%자기애%\" and Content not like \"%자기합리%\" and Content not like \"%분노조절%\" and \\\n",
    "Title not like \"%외상후%\" and Content not like \"%외상후%\" and Content not like \"%과민%\" and Content not like \"%천재지변%\" and Content not like \"%화재%\" and Content not like \"%폭행%\" and Content not like \"%강간%\" and Content not like \"%성추행%\" and Content not like \"%스트레스장애%\" and Content not like \"%PTSD%\" and \\\n",
    "Title not like \"%조울증%\" and Content not like \"%조울증%\" and Content not like \"%양극성%\" and Content not like \"%과대망상%\" and Content not like \"%조증%\" and Content not like \"%경조증%\" and Content not like \"%혼합삽화%\" and \\\n",
    "Title not like \"%섭식장애%\" and Content not like \"%섭식장애%\" and Content not like \"%폭식%\" and Content not like \"%거식%\" and Content not like \"%식이장애%\" and Content not like \"%식욕부진%\" and Content not like \"%대식증%\" and Content not like \"%과식%\" and \\\n",
    "Title not like \"%불안장애%\" and Content not like \"%불안장애%\" and Content not like \"%불안%\" and Content not like \"%공포%\" and Content not like \"%불면증%\" and Content not like \"%수면장애%\" and \\\n",
    "Title not like \"%공황장애%\" and Content not like \"%공황장애%\" and \\\n",
    "Title not like \"%우울증%\" and Content not like \"%우울증%\" and Content not like \"%우울%\" and Content not like \"%슬픔%\" and Content not like \"%무기력%\" and Content not like \"%자살%\" and Content not like \"%죄책감%\" and Content not like \"%화병%\"')\n",
    "freeboard = cur.fetchall()\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-cafe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"raw_data.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "# cur.execute('select * from data')\n",
    "# all_data_community = cur.fetchall() #모든 게시물 추출 149211개\n",
    "\n",
    "#Group1 \n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%정서장애%\" or category is not \"5\" and Content like \"%정서장애%\" or category is not \"5\" and Content like \"%감정장애%\" or category is not \"5\" and Content like \"%기분장애%\" or category is not \"5\" and Content like \"%가을타다%\" or category is not \"5\" and Content like \"%청동장애%\" or Content like \"%계절성%\"')\n",
    "sad = cur.fetchall() #정서장애키워드 있는 게시물 추출 6개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%ADHD%\" or category is not \"5\" and Content like \"%ADHD%\" or category is not \"5\" and Content like \"%주의력%\" or category is not \"5\" and Content like \"%부주의%\" or category is not \"5\" and Content like \"%주의점%\" or category is not \"5\" and Content like \"%산만%\" or category is not \"5\" and Content like \"%과잉행동%\" or category is not \"5\" and Content like \"%충동%\"  or category is not \"5\" and Content like \"%수다%\"')\n",
    "adhd = cur.fetchall() #ADHD키워드 있는 게시물 추출 1064개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%조현병%\" or category is not \"5\" and Content like \"%조현병%\" or category is not \"5\" and Content like \"%망상%\" or category is not \"5\" and Content like \"%환각%\" or category is not \"5\" and Content like \"%사고장애%\" or category is not \"5\" and Content like \"%정신운동장애%\" or category is not \"5\" and Content like \"%인사불성%\" or category is not \"5\" and Content like \"%강직%\" or category is not \"5\" and Content like \"%따라함%\"')\n",
    "schizophrenia = cur.fetchall() #조현병키워드 있는 게시물 추출 452개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%강박장애%\" or category is not \"5\" and Content like \"%강박장애%\" or category is not \"5\" and Content like \"%강박%\" or category is not \"5\" and Content like \"%제자리%\" or category is not \"5\" and Content like \"%집착%\" or category is not \"5\" and Content like \"%결벽증%\" or category is not \"5\" and Content like \"%결벽%\" or category is not \"5\" and Content like \"%깔끔%\" or category is not \"5\" and Content like \"%원위치%\"')\n",
    "ocd = cur.fetchall() #강박장애키워드 있는 게시물 추출 2330개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%인격장애%\" or category is not \"5\" and Content like \"%인격장애%\" or category is not \"5\" and Content like \"%성격장애%\" or category is not \"5\" and Content like \"%변덕%\" or category is not \"5\" and Content like \"%불안정%\" or category is not \"5\" and Content like \"%양가감정%\" or category is not \"5\" and Content like \"%자기애%\" or category is not \"5\" and Content like \"%자기합리%\" or category is not \"5\" and Content like \"%분노조절%\"')\n",
    "borderline = cur.fetchall() #인격장애키워드 있는 게시물 추출 633개\n",
    "\n",
    "# Group2\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%외상후%\" or category is not \"5\" and Content like \"%외상후%\" or category is not \"5\" and Content like \"%과민%\" or category is not \"5\" and Content like \"%천재지변%\" or category is not \"5\" and Content like \"%화재%\" or category is not \"5\" and Content like \"%폭행%\" or category is not \"5\" and Content like \"%강간%\" or category is not \"5\" and Content like \"%성추행%\" or category is not \"5\" and Content like \"%스트레스장애%\" or category is not \"5\" and Content like \"%PTSD%\"')\n",
    "ptsd = cur.fetchall() #외상후(스트레스장애)키워드 있는 게시물 추출 1079개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%조울증%\" or category is not \"5\" and Content like \"%조울증%\" or category is not \"5\" and Content like \"%양극성%\" or category is not \"5\" and Content like \"%과대망상%\" or category is not \"5\" and Content like \"%조증%\" or category is not \"5\" and Content like \"%경조증%\" or category is not \"5\" and Content like \"%혼합삽화%\"')\n",
    "bipolar = cur.fetchall() #조울증키워드 있는 게시물 추출 256개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%섭식장애%\" or category is not \"5\" and Content like \"%섭식장애%\" or category is not \"5\" and Content like \"%폭식%\" or category is not \"5\" and Content like \"%거식%\" or category is not \"5\" and Content like \"%식이장애%\" or category is not \"5\" and Content like \"%식욕부진%\" or category is not \"5\" and Content like \"%대식증%\" or category is not \"5\" and Content like \"%과식%\"')\n",
    "eating = cur.fetchall() #섭식장애키워드 있는 게시물 추출 233개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%불안장애%\" or category is not \"5\" and Content like \"%불안장애%\" or category is not \"5\" and Content like \"%불안%\" or category is not \"5\" and Content like \"%공포%\" or category is not \"5\" and Content like \"%불면증%\" or category is not \"5\" and Content like \"%수면장애%\"')\n",
    "anxiety = cur.fetchall() #불안장애키워드 있는 게시물 추출 4248개\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%공황장애%\" or category is not \"5\" and Content like \"%공황장애%\"')\n",
    "panic = cur.fetchall() #공황(장애)키워드 있는 게시물 추출 223개\n",
    "\n",
    "# Group3\n",
    "cur.execute('select * from data where category is not \"5\" and Title like \"%우울증%\" or category is not \"5\" and Content like \"%우울증%\" or category is not \"5\" and Content like \"%우울%\" or category is not \"5\" and Content like \"%슬픔%\" or category is not \"5\" and Content like \"%무기력%\" or category is not \"5\" and Content like \"%자살%\" or category is not \"5\" and Content like \"%죄책감%\" or category is not \"5\" and Content like \"%화병%\"')\n",
    "depression = cur.fetchall() #우울증키워드 있는 게시물 추출 6917개\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "import ngram_model\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_sad = []\n",
    "for i in range(0,len(sad),1):\n",
    "    temp = tokenizer.tokenize(sad[i][2],{})\n",
    "    token_sad = token_sad + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_sad = ngrams.make_freqlist(token_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_adhd = []\n",
    "for i in range(0,len(adhd),1):\n",
    "    temp = tokenizer.tokenize(adhd[i][2],{})\n",
    "    token_adhd = token_adhd + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_adhd = ngrams.make_freqlist(token_adhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_schizophrenia = []\n",
    "for i in range(0,len(schizophrenia),1):\n",
    "    temp = tokenizer.tokenize(schizophrenia[i][2],{})\n",
    "    token_schizophrenia = token_schizophrenia + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_schizophrenia = ngrams.make_freqlist(token_schizophrenia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_ocd = []\n",
    "for i in range(0,len(ocd),1):\n",
    "    temp = tokenizer.tokenize(ocd[i][2],{})\n",
    "    token_ocd = token_ocd + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_ocd = ngrams.make_freqlist(token_ocd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_borderline = []\n",
    "for i in range(0,len(borderline),1):\n",
    "    temp = tokenizer.tokenize(borderline[i][2],{})\n",
    "    token_borderline = token_borderline + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_borderline = ngrams.make_freqlist(token_borderline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_ptsd = []\n",
    "for i in range(0,len(ptsd),1):\n",
    "    temp = tokenizer.tokenize(ptsd[i][2],{})\n",
    "    token_ptsd = token_ptsd + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_ptsd = ngrams.make_freqlist(token_ptsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_bipolar = []\n",
    "for i in range(0,len(bipolar),1):\n",
    "    temp = tokenizer.tokenize(bipolar[i][2],{})\n",
    "    token_bipolar = token_bipolar + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_bipolar = ngrams.make_freqlist(token_bipolar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_eating = []\n",
    "for i in range(0,len(eating),1):\n",
    "    temp = tokenizer.tokenize(eating[i][2],{})\n",
    "    token_eating = token_eating + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_eating = ngrams.make_freqlist(token_eating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_anxiety = []\n",
    "for i in range(0,len(anxiety),1):\n",
    "    temp = tokenizer.tokenize(anxiety[i][2],{})\n",
    "    token_anxiety = token_anxiety + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_anxiety = ngrams.make_freqlist(token_anxiety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_panic = []\n",
    "for i in range(0,len(panic),1):\n",
    "    temp = tokenizer.tokenize(panic[i][2],{})\n",
    "    token_panic = token_panic + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_panic = ngrams.make_freqlist(token_panic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import korea_nlp_twitter\n",
    "tokenizer = korea_nlp_twitter.Tokenizer()\n",
    "token_depression = []\n",
    "for i in range(0,len(depression),1):\n",
    "    temp = tokenizer.tokenize(depression[i][2],{})\n",
    "    token_depression = token_depression + temp\n",
    "\n",
    "ngrams = ngram_model.Ngram()\n",
    "fre_depression = ngrams.make_freqlist(token_depression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sad_list = list(fre_sad.keys())\n",
    "adhd_list = list(fre_adhd.keys())\n",
    "schizophrenia_list = list(fre_schizophrenia.keys())\n",
    "ocd_list = list(fre_ocd.keys())\n",
    "borderline_list = list(fre_borderline.keys())\n",
    "ptsd_list = list(fre_ptsd.keys())\n",
    "bipolar_list = list(fre_bipolar.keys())\n",
    "eating_list = list(fre_eating.keys())\n",
    "anxiety_list = list(fre_anxiety.keys())\n",
    "panic_list = list(fre_panic.keys())\n",
    "depression_list = list(fre_depression.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = []\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(sad_list),1):\n",
    "    item = sad_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seen = set(all_list)\n",
    "for i in range(0,len(adhd_list),1):\n",
    "    item = adhd_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(schizophrenia_list),1):\n",
    "    item = schizophrenia_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(ocd_list),1):\n",
    "    item = ocd_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set(all_list)\n",
    "for i in range(0,len(borderline_list),1):\n",
    "    item = borderline_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(ptsd_list),1):\n",
    "    item = ptsd_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(bipolar_list),1):\n",
    "    item = bipolar_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seen = set(all_list)\n",
    "for i in range(0,len(eating_list),1):\n",
    "    item = eating_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(anxiety_list),1):\n",
    "    item = anxiety_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(panic_list),1):\n",
    "    item = panic_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)\n",
    "seen = set(all_list)\n",
    "for i in range(0,len(depression_list),1):\n",
    "    item = depression_list[i]\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        all_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33771"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for i in range(0,len(sad),1):\n",
    "    x_train.append(sad[i][2])\n",
    "for i in range(0,len(adhd),1):\n",
    "    x_train.append(adhd[i][2])\n",
    "for i in range(0,len(schizophrenia),1):\n",
    "    x_train.append(schizophrenia[i][2])\n",
    "for i in range(0,len(ocd),1):\n",
    "    x_train.append(ocd[i][2])\n",
    "for i in range(0,len(borderline),1):\n",
    "    x_train.append(borderline[i][2])\n",
    "for i in range(0,len(ptsd),1):\n",
    "    x_train.append(ptsd[i][2])\n",
    "for i in range(0,len(bipolar),1):\n",
    "    x_train.append(bipolar[i][2])\n",
    "for i in range(0,len(eating),1):\n",
    "    x_train.append(eating[i][2])\n",
    "for i in range(0,len(anxiety),1):\n",
    "    x_train.append(anxiety[i][2])\n",
    "for i in range(0,len(panic),1):\n",
    "    x_train.append(panic[i][2])\n",
    "for i in range(0,len(depression),1):\n",
    "    x_train.append(depression[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(0,len(sad),1):\n",
    "    y_train.append(0)\n",
    "for i in range(0,len(adhd),1):\n",
    "    y_train.append(1)\n",
    "for i in range(0,len(schizophrenia),1):\n",
    "    y_train.append(2)\n",
    "for i in range(0,len(ocd),1):\n",
    "    y_train.append(3)\n",
    "for i in range(0,len(borderline),1):\n",
    "    y_train.append(4)\n",
    "for i in range(0,len(ptsd),1):\n",
    "    y_train.append(5)\n",
    "for i in range(0,len(bipolar),1):\n",
    "    y_train.append(6)\n",
    "for i in range(0,len(eating),1):\n",
    "    y_train.append(7)\n",
    "for i in range(0,len(anxiety),1):\n",
    "    y_train.append(8)\n",
    "for i in range(0,len(panic),1):\n",
    "    y_train.append(9)\n",
    "for i in range(0,len(depression),1):\n",
    "    y_train.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(0,len(sad),1):\n",
    "    y_train.append(0)\n",
    "for i in range(0,len(adhd),1):\n",
    "    y_train.append(0)\n",
    "for i in range(0,len(schizophrenia),1):\n",
    "    y_train.append(0)\n",
    "for i in range(0,len(ocd),1):\n",
    "    y_train.append(0)\n",
    "for i in range(0,len(borderline),1):\n",
    "    y_train.append(0)\n",
    "    \n",
    "for i in range(0,len(ptsd),1):\n",
    "    y_train.append(1)\n",
    "for i in range(0,len(bipolar),1):\n",
    "    y_train.append(1)\n",
    "for i in range(0,len(eating),1):\n",
    "    y_train.append(1)\n",
    "for i in range(0,len(anxiety),1):\n",
    "    y_train.append(1)\n",
    "for i in range(0,len(panic),1):\n",
    "    y_train.append(1)\n",
    "    \n",
    "for i in range(0,len(depression),1):\n",
    "    y_train.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17441, 363220)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "vect.fit(x_train)\n",
    "x_train = vect.transform(x_train)\n",
    "print(x_train.shape) #(10, 34)\n",
    "# print(np.array(y_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "ml = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "ml.fit(x_train,y_train)\n",
    "y_pred = ml.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수: 17441, 오류개수: 2375\n",
      "정확도: 0.86\n",
      "f1_score : 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "print('총 테스트 개수: %d, 오류개수: %d' %(len(y_train), (y_train != y_pred).sum()))\n",
    "print('정확도: %.2f' %accuracy_score(y_train, y_pred))\n",
    "print('f1_score : %.2f' %f1_score(y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = ml.predict(cafe_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수: 26791, 오류개수: 14922\n",
      "정확도: 0.44\n",
      "f1_score : 0.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "print('총 테스트 개수: %d, 오류개수: %d' %(len(cafe_y_train), (cafe_y_train != y_pred).sum()))\n",
    "print('정확도: %.2f' %accuracy_score(cafe_y_train, y_pred))\n",
    "print('f1_score : %.2f' %f1_score(cafe_y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.1, learning_rate=1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "model = XGBClassifier(gamma=0.1,learning_rate=1)\n",
    "\n",
    "# x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "# print(x_train.shape[1])\n",
    "# seed = 5\n",
    "# test_size = 0.1\n",
    "# non_cafe_x_train, non_cafe_x_test, non_cafe_y_train, non_cafe_y_test = train_test_split(x_train, y_train, test_size=test_size, random_state=seed)\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3개 그룹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.97%\n",
      "f1_score : 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.79%\n",
      "f1_score : 0.33\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(cafe_x_train)\n",
    "accuracy = accuracy_score(cafe_y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(cafe_y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10개 그룹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.19%\n",
      "f1_score : 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cafe_x_train = vect.transform(cafe_x_train)\n",
    "# print(x_train.shape) #(10, 34)\n",
    "# print(np.array(y_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.25%\n",
      "f1_score : 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(cafe_x_train)\n",
    "accuracy = accuracy_score(cafe_y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(cafe_y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cafe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "con = sqlite3.connect(\"cafe_data.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute('select * from data where category = 3')\n",
    "adhd = cur.fetchall()\n",
    "cur.execute('select * from data where category = 4')\n",
    "borderline = cur.fetchall()\n",
    "cur.execute('select * from data where category = 5')\n",
    "ocd = cur.fetchall()\n",
    "\n",
    "cur.execute('select * from data where category = 0')\n",
    "mania = cur.fetchall()\n",
    "cur.execute('select * from data where category = 2')\n",
    "bipolar = cur.fetchall()\n",
    "cur.execute('select * from data where category = 6')\n",
    "anxiety = cur.fetchall()\n",
    "cur.execute('select * from data where category = 7')\n",
    "panic = cur.fetchall()\n",
    "cur.execute('select * from data where category = 9')\n",
    "ptsd = cur.fetchall()\n",
    "\n",
    "\n",
    "cur.execute('select * from data where category = 1')\n",
    "depression = cur.fetchall()\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cafe_x_train = []\n",
    "cafe_y_train = []\n",
    "for i in range(0,len(adhd),1):\n",
    "    cafe_x_train.append(adhd[i][2])\n",
    "    cafe_y_train.append(0)\n",
    "for i in range(0,len(borderline),1):\n",
    "    cafe_x_train.append(borderline[i][2])\n",
    "    cafe_y_train.append(0)\n",
    "for i in range(0,len(ocd),1):\n",
    "    cafe_x_train.append(ocd[i][2])\n",
    "    cafe_y_train.append(0)\n",
    "for i in range(0,len(mania),1):\n",
    "    cafe_x_train.append(mania[i][2])\n",
    "    cafe_y_train.append(1)\n",
    "for i in range(0,len(bipolar),1):\n",
    "    cafe_x_train.append(bipolar[i][2])\n",
    "    cafe_y_train.append(1)\n",
    "for i in range(0,len(anxiety),1):\n",
    "    cafe_x_train.append(anxiety[i][2])\n",
    "    cafe_y_train.append(1)\n",
    "for i in range(0,len(panic),1):\n",
    "    cafe_x_train.append(panic[i][2])\n",
    "    cafe_y_train.append(1)\n",
    "for i in range(0,len(ptsd),1):\n",
    "    cafe_x_train.append(ptsd[i][2])\n",
    "    cafe_y_train.append(1)\n",
    "for i in range(0,len(depression),1):\n",
    "    cafe_x_train.append(depression[i][2])\n",
    "    cafe_y_train.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cafe_x_train = []\n",
    "cafe_y_train = []\n",
    "for i in range(0,len(adhd),1):\n",
    "    cafe_x_train.append(adhd[i][2])\n",
    "    cafe_y_train.append(1)\n",
    "for i in range(0,len(borderline),1):\n",
    "    cafe_x_train.append(borderline[i][2])\n",
    "    cafe_y_train.append(4)\n",
    "for i in range(0,len(ocd),1):\n",
    "    cafe_x_train.append(ocd[i][2])\n",
    "    cafe_y_train.append(3)\n",
    "for i in range(0,len(mania),1):\n",
    "    cafe_x_train.append(mania[i][2])\n",
    "    cafe_y_train.append(6)\n",
    "for i in range(0,len(bipolar),1):\n",
    "    cafe_x_train.append(bipolar[i][2])\n",
    "    cafe_y_train.append(6)\n",
    "for i in range(0,len(anxiety),1):\n",
    "    cafe_x_train.append(anxiety[i][2])\n",
    "    cafe_y_train.append(8)\n",
    "for i in range(0,len(panic),1):\n",
    "    cafe_x_train.append(panic[i][2])\n",
    "    cafe_y_train.append(9)\n",
    "for i in range(0,len(ptsd),1):\n",
    "    cafe_x_train.append(ptsd[i][2])\n",
    "    cafe_y_train.append(5)\n",
    "for i in range(0,len(depression),1):\n",
    "    cafe_x_train.append(depression[i][2])\n",
    "    cafe_y_train.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_group1 = []\n",
    "test_group2 = []\n",
    "test_group3 = []\n",
    "test_y = []\n",
    "num = 50\n",
    "for i in range(0,len(adhd),1):\n",
    "    if(len(adhd[i][2])>num):\n",
    "        test_group1.append(adhd[i][2])\n",
    "for i in range(0,len(borderline),1):\n",
    "    if(len(borderline[i][2])>num):\n",
    "        test_group1.append(borderline[i][2])\n",
    "for i in range(0,len(ocd),1):\n",
    "    if(len(ocd[i][2])>num):\n",
    "        test_group1.append(ocd[i][2])\n",
    "\n",
    "for i in range(0,len(mania),1):\n",
    "    if(len(mania[i][2])>num):\n",
    "        test_group2.append(mania[i][2])\n",
    "for i in range(0,len(bipolar),1):\n",
    "    if(len(bipolar[i][2])>num):\n",
    "        test_group2.append(bipolar[i][2])\n",
    "for i in range(0,len(anxiety),1):\n",
    "    if(len(anxiety[i][2])>num):\n",
    "        test_group2.append(anxiety[i][2])\n",
    "for i in range(0,len(panic),1):\n",
    "    if(len(panic[i][2])>num):\n",
    "        test_group2.append(panic[i][2])\n",
    "for i in range(0,len(ptsd),1):\n",
    "    if(len(ptsd[i][2])>num):\n",
    "        test_group2.append(ptsd[i][2])\n",
    "\n",
    "        \n",
    "for i in range(0,len(depression),1):\n",
    "    if(len(depression[i][2])>num):\n",
    "        test_group3.append(depression[i][2])\n",
    "    if(len(depression[i][2])>num):\n",
    "        test_y.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "ml = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "ml.fit(cafe_x_train,cafe_y_train)\n",
    "y_pred = ml.predict(cafe_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.83%\n",
      "f1_score : 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = ml.predict(cafe_x_train)\n",
    "accuracy = accuracy_score(cafe_y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(cafe_y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.40%\n",
      "f1_score : 0.33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = ml.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.1, learning_rate=1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "model = XGBClassifier(gamma=0.1,learning_rate=1)\n",
    "\n",
    "# x_train = np.array(x_train)\n",
    "cafe_y_train = np.array(cafe_y_train)\n",
    "# print(x_train.shape[1])\n",
    "# seed = 5\n",
    "# test_size = 0.1\n",
    "# non_cafe_x_train, non_cafe_x_test, non_cafe_y_train, non_cafe_y_test = train_test_split(x_train, y_train, test_size=test_size, random_state=seed)\n",
    "\n",
    "model.fit(cafe_x_train,cafe_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.42%\n",
      "f1_score : 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(cafe_x_train)\n",
    "accuracy = accuracy_score(cafe_y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(cafe_y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.13%\n",
      "f1_score : 0.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print('f1_score : %.2f' %f1_score(y_train, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "temp = \"제가 가끔 망상이 있어요 ㅠㅠㅠ 강박증도 조금 있구\"\n",
    "temp = vect.transform([temp])\n",
    "y_pred = model.predict(temp)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
